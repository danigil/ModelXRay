{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added path: /home/danielg/danigil/ModelXRay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mPyTorch version 2.4.0+cu118 available.\u001b[0m\n",
      "\u001b[1;35mTensorFlow version 2.14.0 available.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', '..', '..', '..'))\n",
    "print('added path:', module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from model_xray.zenml.pipelines.data_creation.dataset_compilation import retreive_datasets\n",
    "from model_xray.utils.dataset_utils import *\n",
    "\n",
    "def img_flatten(arr):\n",
    "    return arr.reshape(arr.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_datasets(mc: str, train_x:int, test_xs:Iterable[Union[None, int]] = range(0,24),\n",
    "                            imsize:int=100, imtype:ImageType=ImageType.GRAYSCALE_FOURPART,\n",
    "                            flatten:bool=True, normalize:bool=True):\n",
    "    trainset_name = get_dataset_name(\n",
    "        mc=mc,\n",
    "        ds_type='train',\n",
    "        xs=[train_x, None],\n",
    "        imsize=imsize,\n",
    "        imtype=imtype,\n",
    "    )\n",
    "    testset_names = {i: get_dataset_name(\n",
    "        mc=mc,\n",
    "        ds_type='test',\n",
    "        xs=[i,],\n",
    "        imsize=imsize,\n",
    "        imtype=imtype,\n",
    "    ) for i in test_xs}\n",
    "    # print(testset_names)\n",
    "\n",
    "    ret = retreive_datasets(\n",
    "        dataset_names=[trainset_name] + list(testset_names.values())\n",
    "    )\n",
    "\n",
    "    X_train, y_train = ret[trainset_name]\n",
    "    if flatten:\n",
    "        X_train = img_flatten(X_train)\n",
    "\n",
    "    if normalize:\n",
    "        X_train = X_train / 255.0\n",
    "\n",
    "    testsets = {}\n",
    "    for i, testset_name in testset_names.items():\n",
    "        X_test, y_test = ret[testset_name]\n",
    "        if flatten:\n",
    "            X_test = img_flatten(X_test)\n",
    "\n",
    "        if normalize:\n",
    "            X_test = X_test / 255.0\n",
    "\n",
    "        testsets[i] = (X_test, y_test)\n",
    "\n",
    "    return ((X_train, y_train), testsets)\n",
    "\n",
    "mc = 'famous_le_10m'\n",
    "image_type = ImageType.GRAYSCALE_FOURPART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign train: 1.0\n",
      "train: 1.0\n",
      "benign test: 0.2\n",
      "xs8 test: 0.8\n",
      "xs9 test: 0.8\n",
      "xs10 test: 0.8\n",
      "xs11 test: 0.8\n",
      "xs12 test: 0.8\n",
      "xs13 test: 0.8\n",
      "xs14 test: 0.8\n",
      "xs15 test: 0.8\n",
      "xs16 test: 0.8\n",
      "xs17 test: 0.8\n",
      "xs18 test: 0.8\n",
      "xs19 test: 0.8\n",
      "xs20 test: 0.8\n",
      "xs21 test: 0.8\n",
      "xs22 test: 1.0\n",
      "xs23 test: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "x_train = 22\n",
    "(X_train, y_train), testsets = get_train_test_datasets(mc, x_train, range(0,24), imtype=image_type, flatten=True, normalize=False)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1, weights='distance',)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_benign_idxs = np.where(y_train == 0)[0]\n",
    "\n",
    "X_train_benign = X_train[train_benign_idxs]\n",
    "y_train_benign = y_train[train_benign_idxs]\n",
    "\n",
    "\n",
    "print(\"benign train:\", clf.score(X_train_benign, y_train_benign))\n",
    "print(\"train:\", clf.score(X_train, y_train))\n",
    "\n",
    "X_test_benigns, y_test_benigns = testsets[0]\n",
    "\n",
    "print(\"benign test:\", clf.score(X_test_benigns, y_test_benigns))\n",
    "for i in range(8, 24):\n",
    "    X_test, y_test = testsets[i]\n",
    "    print(f\"xs{i} test:\", clf.score(X_test, y_test))\n",
    "# print(\"xs23 test:\", rf.score(X_test_xs23_reshaped, y_test_xs23))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from external_code.AI_Model_Steganalysis.siamese import Siamese2\n",
    "\n",
    "x_train = 22\n",
    "mc = 'famous_le_10m'\n",
    "image_type = ImageType.GRAYSCALE_FOURPART\n",
    "\n",
    "(X_train, y_train), testsets = get_train_test_datasets(mc, x_train, range(0,24), imtype=image_type, flatten=False, normalize=True)\n",
    "\n",
    "X_test_benigns, y_test_benigns = testsets[0]\n",
    "X_test_x, y_test_x = testsets[x_train]\n",
    "\n",
    "model = Siamese2(pretrained=False, img_input_shape=(100,100,1), dist=\"l2\", lr=0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_benigns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 10ms/step - loss: 0.9203\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.2169\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.4914\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7928\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f505c09ce90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from external_code.AI_Model_Steganalysis.siamese import make_triplets, MyThresholdCallback\n",
    "\n",
    "triplets_train = make_triplets(X_train, y_train)\n",
    "\n",
    "\n",
    "def get_samples(triplets, idxs):\n",
    "    anchors = triplets[0][idxs]\n",
    "    positives = triplets[1][idxs]\n",
    "    negatives = triplets[2][idxs]\n",
    "\n",
    "    return [anchors, positives, negatives]\n",
    "\n",
    "model.fit(triplets_train, epochs=5, batch_size=16, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Centroid:\n",
      "knn (centroid) accuracy: 0.6666666666666666\n",
      "\n",
      "Train KNN:\n",
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Centroid:\")\n",
    "ret = model.test_centroid(X_train, y_train, X_train, y_train, is_print=True, apply_transforms=False, knn=True, vanilla=False)\n",
    "\n",
    "print(\"\\nTrain KNN:\")\n",
    "ret = model.test_nn(X_train, y_train, X_train, y_train, is_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Centroid (benigns):\n",
      "knn (centroid) accuracy: 0.2\n",
      "\n",
      "Test KNN (benigns):\n",
      "accuracy: 0.4\n",
      "\n",
      "Test Centroid (train_x):\n",
      "knn (centroid) accuracy: 1.0\n",
      "\n",
      "Test KNN (train_x):\n",
      "accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "X_test = np.concatenate([X_test_benigns])\n",
    "y_test = np.concatenate([y_test_benigns])\n",
    "\n",
    "print(\"\\nTest Centroid (benigns):\")\n",
    "ret = model.test_centroid(X_train, y_train, X_test, y_test, is_print=True, apply_transforms=False, knn=True, vanilla=False)\n",
    "\n",
    "print(\"\\nTest KNN (benigns):\")\n",
    "ret = model.test_nn(X_train, y_train, X_test, y_test, is_print=True)\n",
    "\n",
    "X_test = np.concatenate([X_test_x])\n",
    "y_test = np.concatenate([y_test_x])\n",
    "\n",
    "print(\"\\nTest Centroid (train_x):\")\n",
    "ret = model.test_centroid(X_train, y_train, X_test, y_test, is_print=True, apply_transforms=False, knn=True, vanilla=False)\n",
    "\n",
    "print(\"\\nTest KNN (train_x):\")\n",
    "ret = model.test_nn(X_train, y_train, X_test, y_test, is_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All CNNs, All Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = f\"allcnns_allattacks_train_imsize256\"\n",
    "\n",
    "ret = retreive_datasets(\n",
    "    dataset_names=[dataset_name]\n",
    ")\n",
    "\n",
    "X,y = ret[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 24, 552]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(576, 256, 256)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(y, return_counts=True))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img_flatten(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[y == 0]\n",
    "y_train = y[y == 0]\n",
    "X_test = X[y == 1]\n",
    "y_test = y[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 65536)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        24\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        24\n",
      "   macro avg       0.50      0.46      0.48        24\n",
      "weighted avg       1.00      0.92      0.96        24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielg/micromamba/envs/zenml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danielg/micromamba/envs/zenml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danielg/micromamba/envs/zenml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# clf = KNeighborsClassifier(n_neighbors=11, weights='distance',)\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "# X_train_benign = X_train[y_train == 0]\n",
    "\n",
    "# clf = IsolationForest(max_samples=100)\n",
    "# clf = OneClassSVM()\n",
    "clf = LocalOutlierFactor(n_neighbors=7, novelty=True,)\n",
    "clf.fit(X_train,)\n",
    "\n",
    "def map_outliers(y):\n",
    "    return [0 if i == 1 else 1 for i in y]\n",
    "\n",
    "y_pred_train = map_outliers(clf.predict(X_train))\n",
    "\n",
    "print(\"train: \")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.08      0.15       552\n",
      "\n",
      "    accuracy                           0.08       552\n",
      "   macro avg       0.50      0.04      0.07       552\n",
      "weighted avg       1.00      0.08      0.15       552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielg/micromamba/envs/zenml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danielg/micromamba/envs/zenml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/danielg/micromamba/envs/zenml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = map_outliers(clf.predict(X_test))\n",
    "\n",
    "print(\"test: \")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
